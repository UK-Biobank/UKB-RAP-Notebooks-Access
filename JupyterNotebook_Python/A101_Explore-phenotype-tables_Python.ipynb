<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore phenotype tables\n",
    "\n",
    "> This notebook explains how to connect to the phenotypic database and retrieve information about available tables (using Python)\n",
    "\n",
    "- runtime: 5min \n",
    "- recommended instance: mem1_ssd1_v2_x8\n",
    "- cost: <Â£0.10\n",
    "\n",
    "This notebook depends on:\n",
    "* **A Spark instance**\n",
    "\n",
    "This notebook describes the basics of connecting to phenotype databases and exploring tables and fields.\n",
    "We will use a `dxdata.connect` function to initiate a connection to the database. \n",
    "Next, we will learn how to obtain the project and dataset IDs required to load a dataset.\n",
    "We will iterate through the tables in the dataset and obtain a short description of each table. \n",
    "Finally, we will retrieve the information from one of these tables to local memory, inspect the content, and print the few first rows of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import `dxdata` package for subsequent Spark engine employment\n",
    "### Docs at: https://github.com/dnanexus/OpenBio/blob/master/dxdata/getting_started_with_dxdata.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dxdata\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the dataset\n",
    "\n",
    "In the next step, we need to input your project ID and dataset ID. \n",
    "Use the following shell commands to find the values specific to your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project = os.popen(\"dx env | grep project- | awk -F '\\t' '{print $2}'\").read().rstrip()\n",
    "project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "record = os.popen(\"dx describe *dataset | grep  record- | awk -F ' ' '{print $2}'\").read().rstrip().split('\\n')[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can set a `DATASET_ID` variable, which takes a value: [projectID]:[dataset ID]\n",
    "We use it to define the `dataset` with `dxdata.load_dataset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_ID = project + \":\" + record\n",
    "DATASET_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load dataset\n",
    "dataset = dxdata.load_dataset(id=DATASET_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset\n",
    "\n",
    "In this step, we iterate through the tables in `dataset`, printing the table ID, title, and short description.\n",
    "For example, the `participant` table contains general UK Biobank participant data. \n",
    "Other tables contain specific information, like hospitalization records, \n",
    "death records, GP registration, and COVID-19 results. \n",
    "Different tables might be available in your project - you will see tables associated with fields approved in your application.\n",
    "See more info in UK Biobank Docs [here](https://dnanexus.gitbook.io/uk-biobank-rap/getting-started/working-with-ukb-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Participant [participant]\n",
      "\n",
      "-> COVID19 Test Result Record (England) [covid19_result_england]\n",
      "\n",
      "-> COVID19 Test Result Record (Scotland) [covid19_result_scotland]\n",
      "\n",
      "-> COVID19 Test Result Record (Wales) [covid19_result_wales]\n",
      "\n",
      "-> GP Clinical Event Record [gp_clinical]\n",
      "\n",
      "-> GP Prescription Record [gp_scripts]\n",
      "\n",
      "-> GP Registration Record [gp_registrations]\n",
      "\n",
      "-> Hospitalization Record [hesin]\n",
      "\n",
      "-> Hospital Diagnosis Record [hesin_diag]\n",
      "\n",
      "-> Hospital Operation Record [hesin_oper]\n",
      "\n",
      "-> Hospital Critical Care Record [hesin_critical]\n",
      "\n",
      "-> Hospital Maternity Record [hesin_maternity]\n",
      "\n",
      "-> Hospital Delivery Record [hesin_delivery]\n",
      "\n",
      "-> Hospital Psychiatric Detention Record [hesin_psych]\n",
      "\n",
      "-> Death Record [death]\n",
      "\n",
      "-> Death Cause Record [death_cause]\n",
      "\n",
      "-> omop_death [omop_death]\n",
      "omop_death\n",
      "-> omop_device_exposure [omop_device_exposure]\n",
      "omop_device_exposure\n",
      "-> omop_note [omop_note]\n",
      "omop_note\n",
      "-> omop_observation [omop_observation]\n",
      "omop_observation\n",
      "-> omop_drug_exposure [omop_drug_exposure]\n",
      "omop_drug_exposure\n",
      "-> omop_observation_period [omop_observation_period]\n",
      "omop_observation_period\n",
      "-> omop_person [omop_person]\n",
      "omop_person\n",
      "-> omop_procedure_occurrence [omop_procedure_occurrence]\n",
      "omop_procedure_occurrence\n",
      "-> omop_specimen [omop_specimen]\n",
      "omop_specimen\n",
      "-> omop_visit_detail [omop_visit_detail]\n",
      "omop_visit_detail\n",
      "-> omop_visit_occurrence [omop_visit_occurrence]\n",
      "omop_visit_occurrence\n",
      "-> omop_dose_era [omop_dose_era]\n",
      "omop_dose_era\n",
      "-> omop_drug_era [omop_drug_era]\n",
      "omop_drug_era\n",
      "-> omop_condition_era [omop_condition_era]\n",
      "omop_condition_era\n",
      "-> omop_condition_occurrence [omop_condition_occurrence]\n",
      "omop_condition_occurrence\n",
      "-> omop_measurement [omop_measurement]\n",
      "omop_measurement\n",
      "-> Olink Instance 0 NPX Result [olink_instance_0]\n",
      "\n",
      "-> Olink Instance 2 NPX Result [olink_instance_2]\n",
      "\n",
      "-> Olink Instance 3 NPX Result [olink_instance_3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in dataset.entities:\n",
    "    print('-> ' + _.entity_label_singular + ' [' + _.name + ']' )\n",
    "    print(_.entity_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data from the table\n",
    "\n",
    "Following functions select the `participant` table, retrieve data to local memory, \n",
    "and convert them to [Pandas](https://pandas.pydata.org/) data frame. This approach will work for [smaller record table tables](https://biobank.ctsu.ox.ac.uk/crystal/docs.cgi?id=3) by replacing `participant` with your table of interest, such as `hesin_critical`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "participant = dataset['participant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we select the first 5 fields from the `participant` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Field \"eid\">,\n",
       " <Field \"p3_i0\">,\n",
       " <Field \"p3_i1\">,\n",
       " <Field \"p3_i2\">,\n",
       " <Field \"p3_i3\">]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = participant.fields[0:5]\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we retrieve the data and convert them to a pandas table. \n",
    "\n",
    "We can limit the number of rows retrieved. In the following example, we retrieve the first 100 rows.\n",
    "\n",
    "Record tables do not require the `fields=fields` arguemnt, as they contain a manageable number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "participant_data = participant.retrieve_fields(engine=dxdata.connect(), fields=fields, coding_values=\"replace\", limit=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the step above, we obtain a PySpark DataFrame - a distributed dataset.\n",
    "\n",
    "We assess columns and row count with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, eid: string, p3_i0: string, p3_i1: string, p3_i2: string, p3_i3: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below collects distributed data from PySpark DataFrame and converts it to a pandas table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "participant_data_pd = participant_data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we rename the columns to reflect column titles rather than IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colnames = [_.title for _ in fields]\n",
    "participant_data_pd.columns = colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inspect the content of the table\n",
    "\n",
    "Here we print some basic information about the data in the `participant_data` table.\n",
    "`count` shows the number of columns, `unique` shows the number of unique participants, \n",
    "`top` shows the most common value, and `freq` counts how many times this value is observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "participant_data_pd.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the top rows of the data\n",
    "\n",
    "It is possible to use the `head` function to render the table representing the first five rows in the retrieved table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "participant_data_pd.drop(['Participant ID'], axis=1).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "be0617d24f23f3f0ff0f78cfff875dd0cc8ce9ddccca39efd47dcbfb80ba815b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
=======
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Explore phenotype tables\n","\n","> This notebook explains how to connect to the phenotypic database and retrieve information about available tables (using Python)\n","\n","- runtime: 5min \n","- recommended instance: mem1_ssd1_v2_x8\n","- cost: <Â£0.10\n","\n","This notebook depends on:\n","* **A Spark instance**\n","\n","This notebook describes the basics of connecting to phenotype databases and exploring tables and fields.\n","We will use a `dxdata.connect` function to initiate a connection to the database. \n","Next, we will learn how to obtain the project and dataset IDs required to load a dataset.\n","We will iterate through the tables in the dataset and obtain a short description of each table. \n","Finally, we will retrieve the information from one of these tables to local memory, inspect the content, and print the few first rows of the data.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Import `dxdata` package for subsequent Spark engine employment\n","### Docs at: https://github.com/dnanexus/OpenBio/blob/master/dxdata/getting_started_with_dxdata.ipynb"]},{"cell_type":"code","execution_count":1,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["import dxdata\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["## Connect to the dataset\n","\n","In the next step, we need to input your project ID and dataset ID. \n","Use the following shell commands to find the values specific to your project:"]},{"cell_type":"code","execution_count":2,"metadata":{"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["'project-Ggp13kQJQ7zKy7fqyzq9Jyvp'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["project = os.popen(\"dx env | grep project- | awk -F '\\t' '{print $2}'\").read().rstrip()\n","project"]},{"cell_type":"code","execution_count":3,"metadata":{"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["'record-GgpVF50JFv1q2XV3BQF1JF6B'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["record = os.popen(\"dx describe *dataset | grep  record- | awk -F ' ' '{print $2}'\").read().rstrip().split('\\n')[0]\n","record"]},{"cell_type":"markdown","metadata":{},"source":["Next, we can set a `DATASET_ID` variable, which takes a value: [projectID]:[dataset ID]\n","We use it to define the `dataset` with `dxdata.load_dataset` function."]},{"cell_type":"code","execution_count":4,"metadata":{"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["'project-Ggp13kQJQ7zKy7fqyzq9Jyvp:record-GgpVF50JFv1q2XV3BQF1JF6B'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["DATASET_ID = project + \":\" + record\n","DATASET_ID"]},{"cell_type":"code","execution_count":5,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["#load dataset\n","dataset = dxdata.load_dataset(id=DATASET_ID)"]},{"cell_type":"markdown","metadata":{},"source":["## Explore the dataset\n","\n","In this step, we iterate through the tables in `dataset`, printing the table ID, title, and short description.\n","For example, the `participant` table contains general UK Biobank participant data. \n","Other tables contain specific information, like hospitalization records, \n","death records, GP registration, and COVID-19 results. \n","Different tables might be available in your project - you will see tables associated with fields approved in your application.\n","See more info in UK Biobank Docs [here](https://dnanexus.gitbook.io/uk-biobank-rap/getting-started/working-with-ukb-data)."]},{"cell_type":"code","execution_count":6,"metadata":{"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["-> Participant [participant]\n","\n","-> COVID19 Test Result Record (England) [covid19_result_england]\n","\n","-> COVID19 Test Result Record (Scotland) [covid19_result_scotland]\n","\n","-> COVID19 Test Result Record (Wales) [covid19_result_wales]\n","\n","-> GP Clinical Event Record [gp_clinical]\n","\n","-> GP Prescription Record [gp_scripts]\n","\n","-> GP Registration Record [gp_registrations]\n","\n","-> Hospitalization Record [hesin]\n","\n","-> Hospital Diagnosis Record [hesin_diag]\n","\n","-> Hospital Operation Record [hesin_oper]\n","\n","-> Hospital Critical Care Record [hesin_critical]\n","\n","-> Hospital Maternity Record [hesin_maternity]\n","\n","-> Hospital Delivery Record [hesin_delivery]\n","\n","-> Hospital Psychiatric Detention Record [hesin_psych]\n","\n","-> Death Record [death]\n","\n","-> Death Cause Record [death_cause]\n","\n","-> omop_death [omop_death]\n","omop_death\n","-> omop_device_exposure [omop_device_exposure]\n","omop_device_exposure\n","-> omop_note [omop_note]\n","omop_note\n","-> omop_observation [omop_observation]\n","omop_observation\n","-> omop_drug_exposure [omop_drug_exposure]\n","omop_drug_exposure\n","-> omop_observation_period [omop_observation_period]\n","omop_observation_period\n","-> omop_person [omop_person]\n","omop_person\n","-> omop_procedure_occurrence [omop_procedure_occurrence]\n","omop_procedure_occurrence\n","-> omop_specimen [omop_specimen]\n","omop_specimen\n","-> omop_visit_detail [omop_visit_detail]\n","omop_visit_detail\n","-> omop_visit_occurrence [omop_visit_occurrence]\n","omop_visit_occurrence\n","-> omop_dose_era [omop_dose_era]\n","omop_dose_era\n","-> omop_drug_era [omop_drug_era]\n","omop_drug_era\n","-> omop_condition_era [omop_condition_era]\n","omop_condition_era\n","-> omop_condition_occurrence [omop_condition_occurrence]\n","omop_condition_occurrence\n","-> omop_measurement [omop_measurement]\n","omop_measurement\n","-> Olink Instance 0 NPX Result [olink_instance_0]\n","\n","-> Olink Instance 2 NPX Result [olink_instance_2]\n","\n","-> Olink Instance 3 NPX Result [olink_instance_3]\n","\n"]}],"source":["for _ in dataset.entities:\n","    print('-> ' + _.entity_label_singular + ' [' + _.name + ']' )\n","    print(_.entity_description)"]},{"cell_type":"markdown","metadata":{},"source":["## Retrieve data from the table\n","\n","Following functions select the `participant` table, retrieve data to local memory, \n","and convert them to [Pandas](https://pandas.pydata.org/) data frame. This approach will work for [smaller record table tables](https://biobank.ctsu.ox.ac.uk/crystal/docs.cgi?id=3) by replacing `participant` with your table of interest, such as `hesin_critical`."]},{"cell_type":"code","execution_count":7,"metadata":{"tags":[]},"outputs":[],"source":["participant = dataset['participant']"]},{"cell_type":"markdown","metadata":{},"source":["Here we select the first 5 fields from the `participant` table"]},{"cell_type":"code","execution_count":8,"metadata":{"tags":[]},"outputs":[{"data":{"text/plain":["[<Field \"eid\">,\n"," <Field \"p3_i0\">,\n"," <Field \"p3_i1\">,\n"," <Field \"p3_i2\">,\n"," <Field \"p3_i3\">]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["fields = participant.fields[0:5]\n","fields"]},{"cell_type":"markdown","metadata":{},"source":["Next, we retrieve the data and convert them to a pandas table. \n","\n","We can limit the number of rows retrieved. In the following example, we retrieve the first 100 rows.\n","\n","Record tables do not require the `fields=fields` arguemnt, as they contain a manageable number of columns."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["participant_data = participant.retrieve_fields(engine=dxdata.connect(), fields=fields, coding_values=\"replace\", limit=100)"]},{"cell_type":"markdown","metadata":{},"source":["In the step above, we obtain a PySpark DataFrame - a distributed dataset.\n","\n","We assess columns and row count with the following commands:"]},{"cell_type":"code","execution_count":11,"metadata":{"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["DataFrame[summary: string, eid: string, p3_i0: string, p3_i1: string, p3_i2: string, p3_i3: string]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["participant_data.describe()"]},{"cell_type":"code","execution_count":12,"metadata":{"tags":[]},"outputs":[{"data":{"text/plain":["100"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["participant_data.count()"]},{"cell_type":"markdown","metadata":{},"source":["The command below collects distributed data from PySpark DataFrame and converts it to a pandas table:"]},{"cell_type":"code","execution_count":12,"metadata":{"tags":[]},"outputs":[],"source":["participant_data_pd = participant_data.toPandas()"]},{"cell_type":"markdown","metadata":{},"source":["Finally, we rename the columns to reflect column titles rather than IDs."]},{"cell_type":"code","execution_count":13,"metadata":{"tags":[]},"outputs":[],"source":["colnames = [_.title for _ in fields]\n","participant_data_pd.columns = colnames"]},{"cell_type":"markdown","metadata":{},"source":["\n","## Inspect the content of the table\n","\n","Here we print some basic information about the data in the `participant_data` table.\n","`count` shows the number of columns, `unique` shows the number of unique participants, \n","`top` shows the most common value, and `freq` counts how many times this value is observed."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["participant_data_pd.describe(include='all')"]},{"cell_type":"markdown","metadata":{},"source":["## Print the top rows of the data\n","\n","It is possible to use the `head` function to render the table representing the first five rows in the retrieved table:"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["participant_data_pd.drop(['Participant ID'], axis=1).head()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"be0617d24f23f3f0ff0f78cfff875dd0cc8ce9ddccca39efd47dcbfb80ba815b"}}},"nbformat":4,"nbformat_minor":4}
>>>>>>> d90b26367219ad7bbd8f37eeb319ef2486e1682e

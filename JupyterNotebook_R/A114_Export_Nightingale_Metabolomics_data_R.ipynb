{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0389b40f-954d-4ae6-a2d8-7038f2553904",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Accessing the NMR Metabolomics/Nightingale data\n",
    "\n",
    "This notebook demonstrates how to extract all relevant NMR Metabolomics data from the database, and how to join them together to create a single dataset using R. Please note that this notebook is similar to A105_Export-participant-data_R.ipynb within this repository, but has been tailored specifically for the Metabolomics data.\n",
    "\n",
    "Information on the Metabolomics data available can be found on our Showcase website:\n",
    "- **[Category 220](https://ace.ndph.ox.ac.uk/ukb/label.cgi?id=220)** contains the data for each of the 251 metabolomic biomarkers (e.g. field 23474: 3-Hydroxybutyrate). Please also see the Resources tab within this page for more details on how the data was generated. The [companion document](https://biobank.ndph.ox.ac.uk/showcase/refer.cgi?id=2082) provides information on sample processing, ratio calculations, batch variation and reproducibility (the Phase 3 versions are the most recent).\n",
    "- **[Category 221](https://biobank.ndph.ox.ac.uk/ukb/label.cgi?id=221)** includes any QC warnings associated with individual data points (e.g. field 23774: 3-Hydroxybutyrate, QC Flag)\n",
    "- **[Category 222](https://biobank.ndph.ox.ac.uk/ukb/label.cgi?id=222)** contains other processing measures at a sample level (e.g. field 20282: Processing Batch).\n",
    "\n",
    "\n",
    "All fields in these categories are labelled using [Instancing 2](https://biobank.ndph.ox.ac.uk/showcase/instance.cgi?id=2). This means that Instance_0 = the participants blood sample was collected from the initial assessment visit, Instance_1 = First repeat assessment visit etc. To get the dates that the blood sample was collected, you can join the data to [Field 53](https://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=53) (Date of attending Assessment Centre).\n",
    "\n",
    "Note: If you are extracting all NMR Metabolomics data (with all QC metrics), the final dataset should contain ~500,000 rows (participants) and 790 columns.\n",
    "\n",
    "##### Run info\n",
    "\n",
    "- Runtime: <15 minutes\n",
    "- Instance: mem1_hdd1_v2_x16 \n",
    "- Cost: <£2.00\n",
    "\n",
    "### This notebook depends on \n",
    "A **Spark Instance** - Make sure this option is selected when launching JupyterLab.\n",
    "\n",
    "## 1. Install required packages\n",
    "Function `p_load` from `pacman` loads packages into R. If the given package is missing p_load will automatically install it - this can take a considerable amount of time for a package that needs C or FORTRAN code compilation. The following packages are needed to run this notebook:\n",
    "\n",
    "*Note*: If you wish to rerun this notebook, and avoid having to wait for the installation of the packages, creating a [snapshot](https://documentation.dnanexus.com/user/jupyter-notebooks#environment-snapshotshttps://documentation.dnanexus.com/user/jupyter-notebooks#environment-snapshots) of the environment is useful.\n",
    "\n",
    "- `reticulate` - R-Python interface, required to use the `dxdata` package that connects to Spark database and allows retrieval of phenotypic data\n",
    "- `Stringr` – Used for character manipulation \n",
    "- `Dplyr` – Tabular data manipulation in R\n",
    "- `data.table` – Read data into data.table format \n",
    "- `arrow` - Input/output library for Apache binary files\n",
    "- `readr` - Reading and writing tabular data in R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26716d7b-dab8-4e13-9336-1bedb140e5dc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    " # Load required packages \n",
    "if(!require(pacman)) install.packages(\"pacman\")\n",
    "pacman::p_load(reticulate, stringr, dplyr, data.table, arrow, readr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4ec8c",
   "metadata": {},
   "source": [
    "## 2. Import Python and Define your database\n",
    "To improve the reproducibility of your notebooks and ensure they are portable across projects, it is better not to hardcode the connection to any database or dataset names. Instead, you can use the following code to automatically discover the database and dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab29585d-4b05-46be-a454-3f1ac2ff40e7",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "use_python(\"/opt/conda/bin/python\") #pre-installed python environment that contains dxdata\n",
    "dxdata <- import(\"dxdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccd2ce-197f-4adb-a142-8094ef753f58",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Connect to the dataset\n",
    "project_id <- Sys.getenv('DX_PROJECT_CONTEXT_ID') #find the project ID\n",
    "record_id <- system(\"dx find data --type Dataset --delimiter ',' | awk -F ',' '{print $5}'\" , intern = TRUE) #find the record ID\n",
    "DATASET_ID <- paste0(project_id, \":\", record_id)\n",
    "\n",
    "# The DATASET_ID should be in the following format: 'project-XXXXXXXXXXX:record-YYYYYYYYYYYYYY' \n",
    "# Your project ID can also be found in the settings tab within your UKB-RAP project.\n",
    "# To find the record ID, select the 'manage' tab within your UKB-RAP project, then select the '.dataset' file in the root directory.\n",
    "# The record ID will appear under the 'ID' tab on the file info section on the right hand side of the screen.\n",
    "\n",
    "print(paste0(\"DATASET_ID: \", DATASET_ID))\n",
    "# Note: if you have more than one dataset ID retrieved, you can use the cell below this one to automatically find the most recent one in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7bb29c-6dd9-46c1-8071-99970d2f6f79",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# If you have more than one dataset ID available in your project, use the most recent one:\n",
    "# This function extracts the record ID and its created date:\n",
    "get_record_info <- function(dataset_id) {\n",
    "  out <- system(paste(\"dx describe\", dataset_id), intern = TRUE) # dx describe finds details about the dataset_ids\n",
    "  id_line <- out[grep(\"^ *ID\", out)][1] # extract the the ID line\n",
    "  record_id <- sub(\"^ *ID[[:space:]]+\", \"\", id_line) # get the record ID\n",
    "  \n",
    "  created_line <- out[grep(\"^ *Created[[:space:]]\", out)] #this is the created date/time\n",
    "  created_line <- created_line[!grepl(\"Created by\", created_line)][1] #ignore the \"created by\" information\n",
    "  created <- sub(\"^ *Created[[:space:]]+\", \"\", created_line)\n",
    "  created <- as.POSIXct(created, format = \"%a %b %d %H:%M:%S %Y\", tz = \"UTC\") # Convert date to POSIXct\n",
    "  \n",
    "  data.frame(record_id = record_id, created = created, stringsAsFactors = FALSE) # Return as a data frame\n",
    "}\n",
    "\n",
    "# Apply the function to all dataset IDs and combine the results into one data frame\n",
    "record_id_info <- do.call(rbind, lapply(DATASET_ID, get_record_info))\n",
    "\n",
    "record_id_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0a377-95b1-405e-8981-2e57ba219313",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "record_id <- record_id_info %>%\n",
    "  filter(created == max(created, na.rm = TRUE)) %>%\n",
    "  pull(record_id)\n",
    "\n",
    "record_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038778f-5621-4312-a76b-3620a8853790",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#re-run the dataset id with the selected record ID\n",
    "DATASET_ID <- paste0(project_id, \":\", record_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1aca10-1588-44af-9ee7-94f66d4c01b0",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dataset <- dxdata$load_dataset(id=DATASET_ID) #load the metadata for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ccd5b6-00bc-4eb8-9f28-e862f8cef6ad",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the database and app ID\n",
    "database_path <- system(\"dx find data --class database\", intern =TRUE) #find the path to the database\n",
    "app_substring <- na.omit(str_extract(database_path, '(app\\\\d+_\\\\d+)')) # extract the app ID from the database path\n",
    "database_substring <- str_extract(database_path[str_detect(database_path, app_substring)], 'database-([A-Za-z0-9]+)') %>% tolower()  %>% str_replace(\"database-\", \"database_\") #extract the database name\n",
    "database <- paste0(database_substring, \"__\", app_substring) #generate the final database identifier\n",
    "\n",
    "# The database identifier should be in the following format: database_ZZZZZZZZZZ__appQQQQQQ_NNNNNNNNN'\n",
    "# To manually find your database path, go to the 'manage' tab within your UKB_RAP project, then select the '.database' file in the root directory.\n",
    "# The first part of the database identifier is the file ID (found on the right hand side of the screen). The second part of the identifier is the file name\n",
    "\n",
    "print(paste0(\"database = \", database))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2db3c9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "## 3. Extract the data from the database\n",
    "\n",
    "The NMR metabolomics data is stored within the main participant data. The participant data is split into multiple tables, which can make it difficult to query them via SQL. Functions from `dxdata` via pyspark allow access to the participant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7097d1",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Connect to Pyspark via dxdata\n",
    "engine <- dxdata$connect(dialect=\"hive+pyspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92dd6d",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load in the data from your project\n",
    "dataset = dxdata$load_dataset(id=DATASET_ID)\n",
    "# Select the participant table (this is where the metabolomics data is stored)\n",
    "participant_database = dataset[\"participant\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb6b02",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "##### Get the Corresponding Field Schema Data\n",
    "Importing the schema data from the 'Showcase metadata' folder in the project allows you to explore the list of fields and map field ids to names, making it easier to search within the data.\n",
    "\n",
    "Within the database, fields are identified by:\n",
    "* **Field id**: this correspond to the unique field integer identifier (e.g. 94)\n",
    "* **Field title**: this is the title of the field  (e.g. Diastolic blood pressure, manual reading)\n",
    "* **Field name**: this includes the entity, field id, field instance and array (e.g. 'p94_i0_a0', 'p94_i0_a1', 'p94_i1_a0', 'p94_i1_a1', 'p94_i2_a0', 'p94_i2_a1', 'p94_i3_a0', 'p94_i3_a1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89002c-feee-49e0-b48d-f243c3a9e1fd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load in schema data (this contains searchable field names)\n",
    "field_schema <- fread(\"/mnt/project/Showcase metadata/field.tsv\")\n",
    "\n",
    "# Download the data dictionary schema into the environment (this contains field ids)\n",
    "system(paste0(\"dx extract_dataset \", DATASET_ID, \" -ddd\"), intern = TRUE)\n",
    "\n",
    "# Read in the data dictionary\n",
    "datadict <- data.table::fread(list.files(pattern = \"data_dictionary\\\\.csv$\", full.names = TRUE))\n",
    "\n",
    "\n",
    "print(paste0(\"The data dictionary contains \", nrow(datadict), \" rows.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c745d7-0c47-4b6b-b08b-5c00521a71bc",
   "metadata": {},
   "source": [
    "If you prefer to extract all metabolomics data run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f21c1-eb57-478e-8438-263b500aec10",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the field_schema for all metabolomics data\n",
    "field_ids_of_interest<- field_schema %>% \n",
    "                         filter(main_category %in% c(220,221,222)) %>% # These are all the categories associated with the metabolomics data\n",
    "                         pull(field_id)\n",
    "\n",
    "#If you are extracting all metabolomics fields, you should have 512 fields at this point.\n",
    "print(paste0(length(field_ids_of_interest), \" fields of interest have been identified.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831f500f-ff80-4025-b9ef-3480cf865811",
   "metadata": {
    "tags": []
   },
   "source": [
    "Alternatively, you can select specific fields of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d1f5a-ae63-463c-9dfb-e9b5cf8eb70a",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the field_schema for a specific subset of the metabolomics data\n",
    "field_ids_of_interest<- field_schema %>% \n",
    "                         filter(main_category == 222| # This category includes all the processing indicators (useful for QC)\n",
    "                            title %in% c(\"Acetate\", \"Acetate, QC Flag\", \"Date of attending Assessment Centre\")| #Specific metabolite and its related QC field (names as they appear on showcase)\n",
    "                            field_id==53) %>% #Date of attending assessment centre (used to identify when the blood sample was collected from the participant)  \n",
    "                         pull(field_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3094a6d",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Often Field ids have multiple instances - this function will find all the associated field ids\n",
    "fields_for_id <- function(field) {\n",
    "    regex <- paste0('^p', field, '(?![0-9])')\n",
    "    fields <- dplyr::filter(datadict, stringr::str_detect(name, regex)) %>%\n",
    "        dplyr::pull(name)\n",
    "    return(fields)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e193e-3f27-428b-bd99-ac3f4a984404",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get all data from the database for all fields of interest using the schema data (using the function above)\n",
    "# 'eid' is added manually because it is not included within 'field_schema'\n",
    "complete_field_ids <- c('eid', unlist(lapply(field_ids_of_interest, fields_for_id)))\n",
    "\n",
    "#if you are extracting the full metabolomics data, you should have 790 fields in this list\n",
    "length(complete_field_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef6aae-6cff-4ab6-9f23-ee16db9b115e",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Convert field names into dxdata objects\n",
    "# 'iterate()' is needed because the 'find_fields()' output is an itorator object \n",
    "# The resulting object is a list of `Field` objects (object specific to dxdata).\n",
    "# There will be more than the original 512 field ids here as this includes each field split up by instance and array\n",
    "complete_field_ids <- iterate(participant_database$find_fields(names=complete_field_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d285f7-839d-496b-8ed4-6380a562cccb",
   "metadata": {},
   "source": [
    "##### Assign column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc37be-24dc-4e67-ade2-0b3ede622c7a",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Clean the column names for PySpark retrieval\n",
    "# PySpark columns must have no spaces or punctuation - create a function for this\n",
    "complete_col_names_clean <- lapply(seq_along(complete_field_ids), function(i) {\n",
    "    clean_title <- gsub(\" \", \"_\", complete_field_ids[[i]]$title) # replace spaces with underscores\n",
    "    clean_title <- gsub(\"[^a-zA-Z0-9_]\", \"\", clean_title) # remove special characters\n",
    "    setNames(list(clean_title), complete_field_ids[[i]]$column_name)\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069688b-ba07-447d-8bd3-f0ce5cb10500",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "complete_col_names_clean <- do.call(c, complete_col_names_clean) #run the function above\n",
    "complete_col_names_clean <- dict(complete_col_names_clean) # Convert to a python dictionary\n",
    "\n",
    "#There should be 790 fields here\n",
    "length(complete_col_names_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0fb1c1-e42f-4d26-a2ae-3813a05dafd5",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#create the look up table between the original column names and the clean versions\n",
    "mapping_df <- data.frame(\n",
    "    column_name = sapply(complete_field_ids, function(x) x$column_name),\n",
    "    clean_title = sapply(complete_field_ids, function(x) {\n",
    "        t <- gsub(\" \", \"_\", x$title)\n",
    "        gsub(\"[^A-Za-z0-9_]\", \"\", t) }), stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6a948-57e5-4778-88a2-138198339e49",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Write the complete list of field ids to csv (this is needed when the kernel is restarted below)\n",
    "write.csv(mapping_df, \"field_name_mapping.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d26d5f-71ac-44c4-abec-e1615fa86154",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the data using PySpark - This is the main extraction step, which returns and pyspark df\n",
    "data_of_interest <- participant_database$retrieve_fields(engine=engine, fields=complete_field_ids, column_aliases = complete_col_names_clean)\n",
    "\n",
    "# Note: If an error occurs here, double check that the instance was started with a spark cluster, and that the database path is correct.\n",
    "# In the 'monitor' tab of your project, the Executable column for the instance should contain 'JupyterLab with Spark Cluster'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8786b78-a7e5-479e-8842-b1ad752a7178",
   "metadata": {},
   "source": [
    "## 4. Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fba131-7683-43af-87a1-5199f2ce216f",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Save the PySpark data frame as a parquet file\n",
    "system('hadoop fs -rm -r -f data_of_interest.parquet', intern = TRUE) #remove any previous data saved\n",
    "data_of_interest$write$parquet('data_of_interest.parquet') #write using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69883531",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Copy the parquet file into local env\n",
    "if(dir.exists('data_of_interest.parquet')) unlink(\"data_of_interest.parquet\", recursive=TRUE)\n",
    "system('hadoop dfs -copyToLocal data_of_interest.parquet', intern = TRUE)\n",
    "\n",
    "# This file can then be uploaded to your project, which can be useful particularly for large files:\n",
    "# system(\"dx upload -r data_of_interest.parquet\") \n",
    "# To then use this file at a later date, you can use open_dataset() and collect() within RStudio for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e450163a-3b41-4a54-a46e-cab839bc04d1",
   "metadata": {},
   "source": [
    "## 5. Reading in the Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb154f-8fa4-4a61-bbb7-512578809bdf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Important: Restart the kernel at this point to disconnect from Pyspark. \n",
    "# After restarting the kernel, you will need to reconnect to pyspark to extract any more data (it may be safest to re-run the notebook from the beginning again if so)\n",
    "\n",
    "# Re-load packages \n",
    "if(!require(pacman)) install.packages(\"pacman\")\n",
    "pacman::p_load(reticulate, stringr,  dplyr, data.table, arrow, readr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395a9c9",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load in the parquet file\n",
    "data_of_interest_ds <- arrow::open_dataset('data_of_interest.parquet')\n",
    "\n",
    "#Bring the data in as an R data frame\n",
    "data_of_interest_tbl <- data_of_interest_ds %>% collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c01dc6-a22f-442f-bc76-55d48522b3af",
   "metadata": {},
   "source": [
    "## 6. Optional Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6bb457-383b-4e5c-9c0a-eaac96daa425",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Remove any measurements associsted with a QC_Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b411c8e-8bd7-47ad-9a10-d383579de82f",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Generate a table that maps the metabolite data to the coresponding QC Flag column\n",
    "QC_flag_mapping <- tibble(col = names(data_of_interest_tbl)) %>%\n",
    "  filter(\n",
    "    str_detect(col, \"_Instance_\\\\d+$\"), #find any column that has 'instance' in its name\n",
    "    !str_detect(col, \"_QC_Flag_\") #exclude any QC_Flag columns\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    instance = str_extract(col, \"__Instance_\\\\d+$\"), #find out what instance its from\n",
    "    base = str_remove(col, \"__Instance_\\\\d+$\"), #find the instance suffix\n",
    "    qc_col = paste0(base, \"_QC_Flag\", instance), #create a column for the expected QC_flag column\n",
    "    qc_exists = qc_col %in% names(data_of_interest_tbl) #see if that QC column exists in the data\n",
    "  ) %>% \n",
    "filter(qc_exists==TRUE) %>% #keep the columns that have a corresponding QC_Flag column\n",
    "  select(value_col = col, qc_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e4088-113f-47b7-93c4-88c44cd1a12f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check this here:\n",
    "QC_flag_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb9ebc8-b5cf-4a16-806a-9f4a47227b1e",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_clean <- data_of_interest_tbl\n",
    "\n",
    "for (i in seq_len(nrow(QC_flag_mapping))) { #loop over the QC_flag_mapping table\n",
    "  value <- QC_flag_mapping$value_col[i] #set the value column\n",
    "  qc_flag  <- QC_flag_mapping$qc_col[i] #set the QC_Flag column\n",
    "\n",
    "  data_clean[[value]] <-\n",
    "    replace(\n",
    "      data_clean[[value]], #take the value column\n",
    "      !is.na(data_clean[[qc_flag]]), #if the QC flag is not NA (i.e. there was a QC flag for that data point)\n",
    "      NA #replace the value with NA in the corresponding column\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632667d-4d18-4209-b68f-40c20a72da54",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Convert the field titles to field names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300ab4c-4575-4369-a56c-355c1454ccbc",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#load in file generated that links the original file name to the clean version\n",
    "field_name_mapping <- read_csv(\"field_name_mapping.csv\", show_col_types = FALSE)\n",
    "# Replace the column names \n",
    "new_names <- field_name_mapping$column_name[ match(names(data_clean), field_name_mapping$clean_title) ] \n",
    "names(data_clean) <- new_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513f50c-f0ea-471b-84e6-4b858b93449d",
   "metadata": {},
   "source": [
    "#### Write the data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b01d3",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(data_clean, 'data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e94a4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"dx upload data_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
